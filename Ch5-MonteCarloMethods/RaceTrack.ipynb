{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RaceTrack.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPe+sQu7FB19OC/Ff5rpIg7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chandrusuresh/ReinforcementLearning/blob/master/Ch5-MonteCarloMethods/RaceTrack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToJb-Y89nKVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "%matplotlib inline\n",
        "from tqdm import tqdm\n",
        "from enum import Enum\n",
        "# np.random.seed(0)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzPO2dUE6EDS",
        "colab_type": "text"
      },
      "source": [
        "# Race Track\n",
        "\n",
        "This is the solution to Exercise-5.12 in Page-111 of the book [\"Reinforcement Learning\" by Barto, Sutton](http://incompleteideas.net/sutton/book/the-book.html).\n",
        "\n",
        "The summary of the problem is as follows:\n",
        "1. We have a map of a race track that is discretized by a grid of cells. Each cell corresponds to a position on the race track.\n",
        "2. The goal is to find the optimal path from a set of cells marked start line to another set of cells marked the finish line. For simplicity, the start line is assumed to be in the last row of the grid (bottom) and finish line is assumed to be in the last column of the grid (right).\n",
        "3. The track also has a set of valid & invalid cells. The invalid cells represent obstacles or out-of-bounds. No path is allowed to pass through an obstacle.\n",
        "4. Each time a path gets on a cell labelled obstacle, the position resets to a random start cell and the episode continues. The episode ends with the final state vector passes through or gets to any cell labeled finish line.\n",
        "5. The state vector is given by the position and velocity in the x & y directions. i.e. $\\text{state} = [p_x,p_y,v_x,v_y]$ where $p,v$ represent the position and velocity.\n",
        "5. The input vector is the acceleration at each time step given by: $\\text{input} = [a_x,a_y]$ where $a_x,a_y \\in \\{-1,0,1\\}$. The maximum number of possible actions is therefore (=3 $\\times$ 3) 9.\n",
        "6. In the simplest case, the state transition is a deterministic function of the current state and action. The state transition is computed as follows:\n",
        "$$ \\begin{align*} \\left[\\begin{matrix} p_x \\\\p_y \\\\ v_x \\\\ v_y\\end{matrix} \\right]_{k+1} &= \\left[ \\begin{matrix} 1 & 0 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\end{matrix}\\right] \\left[\\begin{matrix} p_x \\\\p_y \\\\ v_x \\\\ v_y\\end{matrix} \\right]_{k}+ \\left[ \\begin{matrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 0 \\\\ 0 & 1 \\end{matrix}\\right] \\left[ \\begin{matrix} a_x \\\\ a_y \\end{matrix}\\right]_k \\\\ \\\\\n",
        "\\Rightarrow s_{k+1} &= A s_k + B a_k \\end{align*}$$\n",
        "\n",
        "##### **Bonus Challenge**\n",
        "8. The above deterministic transition condition is relaxed as follows where the velocity increments (accleration input) are 0 with probability 0.1\n",
        "$$ \\Rightarrow s_{k+1} = \\Bigg\\{ \\begin{matrix} A s_k + B a_k & \\text{with probabilty=0.9} \\\\ A s_k & \\text{with probabilty=0.1} \\end{matrix}$$ \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Odvgucmx4eFL",
        "colab_type": "text"
      },
      "source": [
        "### Initialize Tracks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS5tWIN7paU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VALID = 0\n",
        "START = 1\n",
        "PATH = 2\n",
        "FINISH = 3\n",
        "OBSTACLE = 4\n",
        "\n",
        "def get_circuits():\n",
        "  nRows_1 = 32\n",
        "  nCols_1 = 17\n",
        "  map_1 = np.zeros((nRows_1,nCols_1),dtype=np.int8)\n",
        "  map_1[-1,3:9] = START\n",
        "  map_1[0:6,-1] = FINISH\n",
        "  map_1[-3:,:3] = OBSTACLE\n",
        "  map_1[-10:-3:,:2] = OBSTACLE\n",
        "  map_1[-18:-10:,:1] = OBSTACLE\n",
        "  map_1[0,:3] = OBSTACLE\n",
        "  map_1[1:3,:2] = OBSTACLE\n",
        "  map_1[3,:1] = OBSTACLE\n",
        "  map_1[7:,9:] = OBSTACLE\n",
        "  map_1[6,10:] = OBSTACLE\n",
        "\n",
        "  nRows_2 = 30\n",
        "  nCols_2 = 32\n",
        "  map_2 = np.zeros((nRows_2,nCols_2),dtype=np.int8)\n",
        "  map_2[-1,:23] = START\n",
        "  map_2[0:9,-1] = FINISH\n",
        "  map_2[-17:,23:] = OBSTACLE\n",
        "  map_2[-18:,24:] = OBSTACLE\n",
        "  map_2[-19:,26:] = OBSTACLE\n",
        "  map_2[-20:,27:] = OBSTACLE\n",
        "  map_2[-21:,30:] = OBSTACLE\n",
        "  map_2[0,:16] = OBSTACLE\n",
        "  map_2[[1,8],:13] = OBSTACLE\n",
        "  map_2[[2,7],:12] = OBSTACLE\n",
        "  map_2[3:7,:11] = OBSTACLE\n",
        "  map_2[9:14,:14] = OBSTACLE\n",
        "  c = 1\n",
        "  for i in range(14,nRows_2-2):\n",
        "    map_2[i,:14-c] = OBSTACLE\n",
        "    c += 1\n",
        "  return map_1,map_2\n",
        "\n",
        "def plot_circuit(fig,map,num):\n",
        "  nRows,nCols = map.shape\n",
        "  # create discrete colormap\n",
        "  #cmap = colors.ListedColormap(['red', 'blue'])\n",
        "  cmap = colors.ListedColormap(['white','red','blue','green','black'])\n",
        "  bounds = [0,0.1,3]\n",
        "  norm = colors.BoundaryNorm(bounds, cmap.N)\n",
        "  ax = fig.add_subplot(1,2,num)\n",
        "  ax.imshow(map, cmap=cmap)#, norm=norm)\n",
        "\n",
        "  ### draw gridlines\n",
        "  # ax = plt.gca();\n",
        "  ax.set_xticks(np.arange(-0.5, nCols+0.5, 1));\n",
        "  ax.set_yticks(np.arange(-0.5, nRows+0.5, 1));\n",
        "  ax.set_xticklabels(np.arange(-0.5, nCols+0.5, 1));\n",
        "  ax.set_yticklabels(np.arange(-0.5, nRows+0.5, 1));\n",
        "  ax.grid(color='k', linestyle='-', linewidth=1)\n",
        "\n",
        "  ax.set_xticklabels([])\n",
        "  ax.set_yticklabels([])\n",
        "  ax.xaxis.set_ticks_position('none')\n",
        "  ax.yaxis.set_ticks_position('none')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvRmT82s4hvM",
        "colab_type": "text"
      },
      "source": [
        "### Visualize Race Tracks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qyW-kHqz-Va",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "d6244b28-07df-4c01-8562-a222c2818166"
      },
      "source": [
        "map_1,map_2 = get_circuits()\n",
        "fig = plt.figure(figsize=(20,7))#20,7)\n",
        "plot_circuit(fig,map_1,1)\n",
        "plot_circuit(fig,map_2,2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wt-hLA3pBg74",
        "colab_type": "text"
      },
      "source": [
        "### Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ43rrCTBkD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_velocity = 5\n",
        "actions = np.array([[-1,-1],[-1,0],[-1,1],[0,-1],[0,0],[0,1],[1,-1],[1,0],[1,1]])\n",
        "gamma = 1.0\n",
        "A_mat = np.matrix([[1,0,1,0],[0,1,0,1],[0,0,1,0],[0,0,0,1]])\n",
        "B_mat = np.matrix([[1,0],[0,1],[1,0],[0,1]])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7J-6EiFmSPr",
        "colab_type": "text"
      },
      "source": [
        "## Path Finding\n",
        "\n",
        "First, we try to solve the relax the optimal requirement in the problem statement and focus just on being able to find a feasible trajectory from the start to finish line. For this, the Monte-Carlo Off-policy control algorithm in Page-111 of the book is used.\n",
        "1. Behavior policy. The behavior policy is set up to allow exploration of all states and satisfy the problem constraints simultaneously.\n",
        "2. The behavior policy is made restrictive to satisfy the problem constraints to allow more valid control inputs through the MC simulation. This allows a greater fraction of the episodes to terminate and leads to more coverage. In addition, encoding the known constraints in the behavior policy does not hurt exploration in any way. Some of these constraints are encoded in the behavior policy are as follows: \n",
        "\n",
        "*   The path is forbidden to leave the grid from the initial state. This is redundant since the condition for out-of-bounds is checked every step, but is included to speed up convergence\n",
        "*   The velocity components cannot both be zero at any cell other than the start line. This means that any action that makes the speed zero in any valid cell is forbidden by the behavior policy\n",
        "*   The speeds in both directions cannot exceed the max speed limit of 5 units. So the acceleration inputs that increase/decrease the velocith below this threshold are forbidden.\n",
        "\n",
        ">   The behavior policy chooses the actions that satisfy the above constraints with equal probability.\n",
        "\n",
        "3. This part of the problem focusses only on path-finding, therefore the reward is therefore modified to be terminal and all states in the trajectory are given a reward of +1 on reaching the finish line and -1 for going out-of-bounds.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-rplh5P5KOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_state(map):\n",
        "  find_start_line = np.where(map == START)\n",
        "  start_line = np.array(list(zip(find_start_line[0],find_start_line[1])))\n",
        "  choice = np.random.choice(range(start_line.shape[0]))\n",
        "  init = [start_line[choice,0],start_line[choice,1],0,0]\n",
        "  return init\n",
        "\n",
        "def check_termination(map,curr_state):\n",
        "  finish_line = np.where(map == FINISH)\n",
        "  return curr_state[1] >= finish_line[1][0] and curr_state[0] >= np.min(finish_line[0]) and curr_state[0] <= np.max(finish_line[0])\n",
        "\n",
        "def check_OutOfBounds(map,curr_state):\n",
        "  if min(curr_state[0],curr_state[1]) < 0:\n",
        "    return True\n",
        "  elif check_termination(map,curr_state):\n",
        "    return False\n",
        "  elif curr_state[1] >= map.shape[1] or curr_state[0] >= map.shape[0]:\n",
        "    return True\n",
        "  return map[curr_state[0],curr_state[1]] == OBSTACLE\n",
        "\n",
        "def is_init(map,state):\n",
        "  return map[state[0],state[1]] == START\n",
        "\n",
        "def move(state,input):\n",
        "  new_vel = [state[2]+input[0],state[3]+input[1]]\n",
        "  new_state = [state[0]+new_vel[0],state[1]+new_vel[1]] + new_vel\n",
        "  return new_state,new_vel\n",
        "\n",
        "def behavior_policy(map,state):\n",
        "  act_idx = np.arange(actions.shape[0])\n",
        "  prob = 1\n",
        "  if is_init(map,state):\n",
        "    idx = np.where(actions[:,0] < 0)[0]\n",
        "    prob = 1/float(len(idx))\n",
        "    act_idx = idx\n",
        "  # elif state[2]==0 and state[3] == 0:\n",
        "  #   idx = np.arange(actions.shape[0])\n",
        "  #   act_idx = np.delete(idx,[4])\n",
        "  #   prob = 1/float(len(act_idx))\n",
        "  else:\n",
        "    idx = [i for i in range(actions.shape[0]) if state[2]+actions[i,0] == 0 and state[3]+actions[i,1] == 0]\n",
        "    act_idx = np.delete(act_idx,idx)\n",
        "    prob = 1/float(len(act_idx))\n",
        "  if state[2] == max_velocity:\n",
        "    idx = np.where(actions[:,0] < 1)[0]\n",
        "    prob = 1/float(len(idx))\n",
        "    act_idx = idx\n",
        "  elif state[2] == -max_velocity:\n",
        "    idx = np.where(actions[:,0] > -1)[0]\n",
        "    prob = 1/float(len(idx))\n",
        "    act_idx = idx\n",
        "  if state[3] == max_velocity:\n",
        "    idx = np.where(actions[act_idx,1] < 1)[0]\n",
        "    prob = 1/float(len(idx))\n",
        "    act_idx = act_idx[idx]\n",
        "  elif state[3] == -max_velocity:\n",
        "    idx = np.where(actions[act_idx,1] > -1)[0]\n",
        "    prob = 1/float(len(idx))\n",
        "    act_idx = act_idx[idx]\n",
        "  if len(act_idx) == actions.shape[0]:\n",
        "    prob = 1/float(actions.shape[0])\n",
        "    act_idx = [np.random.choice(range(actions.shape[0]))]\n",
        "  return actions[np.random.choice(act_idx),:],np.round(prob,3)\n",
        "\n",
        "def get_action_idx(action):\n",
        "  return np.where(np.sum(np.abs(actions-action),1) == 0)[0][0]\n",
        "\n",
        "def play(map,init):\n",
        "  curr_state = np.copy(init)\n",
        "  reward = 0\n",
        "  traj = [curr_state]\n",
        "  action_prob = []\n",
        "  while not check_termination(map,curr_state):\n",
        "    reward -= 1\n",
        "    act,prob = behavior_policy(map,curr_state)\n",
        "    next_state,new_vel = move(curr_state,act)\n",
        "    # print(\"################\")\n",
        "    # print(curr_state)\n",
        "    # print(new_vel)\n",
        "    # print(next_state)\n",
        "    if check_OutOfBounds(map,next_state):\n",
        "      return -1,traj,action_prob\n",
        "      # curr_state = init_state(map)\n",
        "      # traj = [curr_state]\n",
        "      # action_prob = []\n",
        "      # continue\n",
        "    else:\n",
        "      curr_state = next_state\n",
        "    action_prob += [list(act) + [prob]]\n",
        "    traj += [curr_state]\n",
        "  return 1,traj,action_prob\n",
        "\n",
        "def target_policy(Q,state):\n",
        "  best_action = [np.argmax(Q[state[0],state[1],max_velocity+state[2],max_velocity+state[3],:])]\n",
        "  if len(best_action) < 1:\n",
        "    print('No Best Action')\n",
        "    print('State:',state)\n",
        "    print('Action:',Q[state[0],state[1],:])\n",
        "  return np.random.choice(best_action),np.round(1/float(len(best_action)),3)\n",
        "\n",
        "def play_target(map,Q,init):\n",
        "  curr_state = np.copy(init)\n",
        "  reward = 0\n",
        "  traj = [curr_state]\n",
        "  action_prob = []\n",
        "  while not check_termination(map,curr_state):\n",
        "    reward -= 1\n",
        "    a,prob = target_policy(Q,curr_state)\n",
        "    act = actions[a]\n",
        "    new_vel = [curr_state[2]+act[0],curr_state[3]+act[1]]\n",
        "    next_state = [curr_state[0]+new_vel[0],curr_state[1]+new_vel[1],new_vel[0],new_vel[1]] \n",
        "    if check_OutOfBounds(map,next_state):\n",
        "      # curr_state = init_state(map)\n",
        "      break\n",
        "    else:\n",
        "      curr_state = next_state\n",
        "    action_prob += [list(act) + [prob]]\n",
        "    traj += [curr_state]\n",
        "  return reward,traj,action_prob\n",
        "\n",
        "def MonteCarlo_OffPolicyControl(map,num_episodes):\n",
        "  nRows,nCols = map.shape\n",
        "  action_values  = np.zeros((nRows,nCols,2*max_velocity+1,2*max_velocity+1,len(actions)))\n",
        "  action_weights = np.zeros((nRows,nCols,2*max_velocity+1,2*max_velocity+1,len(actions)))\n",
        "\n",
        "  for episode in tqdm(range(num_episodes)):\n",
        "    init = init_state(map)\n",
        "    reward,traj,action_prob = play(map,init)\n",
        "    G = 0\n",
        "    W = 1\n",
        "    for i in range(len(traj)-2,-1,-1):\n",
        "      t = traj[i]\n",
        "      act_prob = action_prob[i]\n",
        "      G = reward#gamma*G + reward\n",
        "      act_idx = get_action_idx(np.array(act_prob[:2]))\n",
        "      action_weights[t[0],t[1],max_velocity+t[2],max_velocity+t[3],act_idx] += W\n",
        "      action_values[t[0],t[1],max_velocity+t[2],max_velocity+t[3],act_idx] += W/action_weights[t[0],t[1],max_velocity+t[2],max_velocity+t[3],act_idx]*(G-action_values[t[0],t[1],max_velocity+t[2],max_velocity+t[3],act_idx])\n",
        "      pi_t,_ = target_policy(action_values,t)\n",
        "      if pi_t != act_idx:\n",
        "        break\n",
        "      W = W/act_prob[-1]\n",
        "  return action_values\n",
        "\n",
        "def generate_path(map,Q):\n",
        "  final_map = []\n",
        "  for k in range(2):\n",
        "    init = init_state(map)\n",
        "    reward,traj,action_prob = play_target(map,Q,init)\n",
        "    print('Reward = :',reward)\n",
        "    final_map.append(np.copy(map))\n",
        "    for i,t in enumerate(traj):\n",
        "      final_map[-1][min(t[0],map.shape[0]-1),min(t[1],map.shape[1]-1)] = PATH\n",
        "  fig = plt.figure(figsize=(20,7))\n",
        "  plot_circuit(fig,final_map[0],1)\n",
        "  plot_circuit(fig,final_map[1],2)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoMxzO-Ar5Qb",
        "colab_type": "text"
      },
      "source": [
        "## Monte-Carlo Off-Policy Control"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym8vTXuD4Yta",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "00f9b680-2fc2-47de-8550-45a96b184a85"
      },
      "source": [
        "num_episodes = 100000\n",
        "\n",
        "Q1 = MonteCarlo_OffPolicyControl(map_1,num_episodes)\n",
        "\n",
        "Q2 = MonteCarlo_OffPolicyControl(map_2,num_episodes)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [00:58<00:00, 1721.79it/s]\n",
            "100%|██████████| 100000/100000 [01:31<00:00, 1094.17it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWxqZOLa1mPI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "459f4606-9c1c-4be8-f208-33ee91e938eb"
      },
      "source": [
        "generate_path(map_1,Q1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reward = : -18\n",
            "Reward = : -13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLJxeHhhvavI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "e145c052-9ac3-440d-b547-37f2e9530999"
      },
      "source": [
        "generate_path(map_2,Q2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reward = : -12\n",
            "Reward = : -9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}