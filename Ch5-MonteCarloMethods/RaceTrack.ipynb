{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RaceTrack.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPqgHO8R8MG5hD/FGgNM72X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chandrusuresh/ReinforcementLearning/blob/master/Ch5-MonteCarloMethods/RaceTrack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToJb-Y89nKVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "%matplotlib inline\n",
        "from tqdm import tqdm\n",
        "from enum import Enum\n",
        "# np.random.seed(0)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzPO2dUE6EDS",
        "colab_type": "text"
      },
      "source": [
        "# Race Track\n",
        "\n",
        "This is the solution to Exercise-5.12 in Page-111 of the book [\"Reinforcement Learning\" by Barto, Sutton](http://incompleteideas.net/sutton/book/the-book.html).\n",
        "\n",
        "The summary of the problem is as follows:\n",
        "1. We have a map of a race track that is discretized by a grid of cells. Each cell corresponds to a position on the race track.\n",
        "2. The goal is to find the optimal path from a set of cells marked start line to another set of cells marked the finish line. For simplicity, the start line is assumed to be in the last row of the grid (bottom) and finish line is assumed to be in the last column of the grid (right).\n",
        "3. The track also has a set of valid & invalid cells. The invalid cells represent obstacles or out-of-bounds. No path is allowed to pass through an obstacle.\n",
        "4. Each time a path gets on a cell labelled obstacle, the position resets to a random start cell and the episode continues. The episode ends with the final state vector passes through or gets to any cell labeled finish line.\n",
        "5. The state vector is given by the position and velocity in the x & y directions. i.e. $\\text{state} = [p_x,p_y,v_x,v_y]$ where $p,v$ represent the position and velocity.\n",
        "5. The input vector is the acceleration at each time step given by: $\\text{input} = [a_x,a_y]$ where $a_x,a_y \\in \\{-1,0,1\\}$. The maximum number of possible actions is therefore (=3 $\\times$ 3) 9.\n",
        "6. In the simplest case, the state transition is a deterministic function of the current state and action. The state transition is computed as follows:\n",
        "$$ \\begin{align*} \\left[\\begin{matrix} p_x \\\\p_y \\\\ v_x \\\\ v_y\\end{matrix} \\right]_{k+1} &= \\left[ \\begin{matrix} 1 & 0 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\end{matrix}\\right] \\left[\\begin{matrix} p_x \\\\p_y \\\\ v_x \\\\ v_y\\end{matrix} \\right]_{k}+ \\left[ \\begin{matrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 0 \\\\ 0 & 1 \\end{matrix}\\right] \\left[ \\begin{matrix} a_x \\\\ a_y \\end{matrix}\\right]_k \\\\ \\\\\n",
        "\\Rightarrow s_{k+1} &= A s_k + B a_k \\end{align*}$$\n",
        "\n",
        "##### **Bonus Challenge**\n",
        "8. The above deterministic transition condition is relaxed as follows where the velocity increments (accleration input) are 0 with probability 0.1\n",
        "$$ \\Rightarrow s_{k+1} = \\Bigg\\{ \\begin{matrix} A s_k + B a_k & \\text{with probabilty=0.9} \\\\ A s_k & \\text{with probabilty=0.1} \\end{matrix}$$ \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Odvgucmx4eFL",
        "colab_type": "text"
      },
      "source": [
        "### Initialize Tracks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS5tWIN7paU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VALID = 0\n",
        "START = 1\n",
        "PATH = 2\n",
        "FINISH = 3\n",
        "OBSTACLE = 4\n",
        "\n",
        "def get_circuits():\n",
        "  nRows_1 = 32\n",
        "  nCols_1 = 17\n",
        "  map_1 = np.zeros((nRows_1,nCols_1),dtype=np.int8)\n",
        "  map_1[-1,3:9] = START\n",
        "  map_1[0:6,-1] = FINISH\n",
        "  map_1[-3:,:3] = OBSTACLE\n",
        "  map_1[-10:-3:,:2] = OBSTACLE\n",
        "  map_1[-18:-10:,:1] = OBSTACLE\n",
        "  map_1[0,:3] = OBSTACLE\n",
        "  map_1[1:3,:2] = OBSTACLE\n",
        "  map_1[3,:1] = OBSTACLE\n",
        "  map_1[7:,9:] = OBSTACLE\n",
        "  map_1[6,10:] = OBSTACLE\n",
        "\n",
        "  nRows_2 = 30\n",
        "  nCols_2 = 32\n",
        "  map_2 = np.zeros((nRows_2,nCols_2),dtype=np.int8)\n",
        "  map_2[-1,:23] = START\n",
        "  map_2[0:9,-1] = FINISH\n",
        "  map_2[-17:,23:] = OBSTACLE\n",
        "  map_2[-18:,24:] = OBSTACLE\n",
        "  map_2[-19:,26:] = OBSTACLE\n",
        "  map_2[-20:,27:] = OBSTACLE\n",
        "  map_2[-21:,30:] = OBSTACLE\n",
        "  map_2[0,:16] = OBSTACLE\n",
        "  map_2[[1,8],:13] = OBSTACLE\n",
        "  map_2[[2,7],:12] = OBSTACLE\n",
        "  map_2[3:7,:11] = OBSTACLE\n",
        "  map_2[9:14,:14] = OBSTACLE\n",
        "  c = 1\n",
        "  for i in range(14,nRows_2-2):\n",
        "    map_2[i,:14-c] = OBSTACLE\n",
        "    c += 1\n",
        "  return map_1,map_2\n",
        "\n",
        "def plot_circuit(fig,map,num):\n",
        "  nRows,nCols = map.shape\n",
        "  # create discrete colormap\n",
        "  #cmap = colors.ListedColormap(['red', 'blue'])\n",
        "  cmap = colors.ListedColormap(['white','red','blue','green','black'])\n",
        "  bounds = [0,0.1,3]\n",
        "  norm = colors.BoundaryNorm(bounds, cmap.N)\n",
        "  ax = fig.add_subplot(1,2,num)\n",
        "  ax.imshow(map, cmap=cmap)#, norm=norm)\n",
        "\n",
        "  ### draw gridlines\n",
        "  # ax = plt.gca();\n",
        "  ax.set_xticks(np.arange(-0.5, nCols+0.5, 1));\n",
        "  ax.set_yticks(np.arange(-0.5, nRows+0.5, 1));\n",
        "  ax.set_xticklabels(np.arange(-0.5, nCols+0.5, 1));\n",
        "  ax.set_yticklabels(np.arange(-0.5, nRows+0.5, 1));\n",
        "  ax.grid(color='k', linestyle='-', linewidth=1)\n",
        "\n",
        "  ax.set_xticklabels([])\n",
        "  ax.set_yticklabels([])\n",
        "  ax.xaxis.set_ticks_position('none')\n",
        "  ax.yaxis.set_ticks_position('none')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvRmT82s4hvM",
        "colab_type": "text"
      },
      "source": [
        "### Visualize Race Tracks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qyW-kHqz-Va",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "2ea2e825-5af3-4ed5-8a79-a3ab32ef707c"
      },
      "source": [
        "map_1,map_2 = get_circuits()\n",
        "fig = plt.figure(figsize=(20,7))#20,7)\n",
        "plot_circuit(fig,map_1,1)\n",
        "plot_circuit(fig,map_2,2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wt-hLA3pBg74",
        "colab_type": "text"
      },
      "source": [
        "### Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ43rrCTBkD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_velocity = 5\n",
        "actions = np.array([[-1,-1],[-1,0],[-1,1],[0,-1],[0,0],[0,1],[1,-1],[1,0],[1,1]])\n",
        "gamma = 1.0\n",
        "# A_mat = np.matrix([[1,0,1,0],[0,1,0,1],[0,0,1,0],[0,0,0,1]])\n",
        "# B_mat = np.matrix([[1,0],[0,1],[1,0],[0,1]])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-rplh5P5KOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_state(map):\n",
        "  find_start_line = np.where(map == START)\n",
        "  start_line = np.array(list(zip(find_start_line[0],find_start_line[1])))\n",
        "  choice = np.random.choice(range(start_line.shape[0]))\n",
        "  init = [start_line[choice,0],start_line[choice,1],0,0]\n",
        "  return init\n",
        "\n",
        "def check_termination(map,curr_state):\n",
        "  finish_line = np.where(map == FINISH)\n",
        "  return curr_state[1] > finish_line[1][0] and curr_state[0] >= np.min(finish_line[0]) and curr_state[0] <= np.max(finish_line[0])\n",
        "\n",
        "def check_OutOfBounds(map,curr_state):\n",
        "  if min(curr_state[0],curr_state[1]) < 0:\n",
        "    return True\n",
        "  elif check_termination(map,curr_state):\n",
        "    return False\n",
        "  elif curr_state[1] >= map.shape[1] or curr_state[0] >= map.shape[0]:\n",
        "    return True\n",
        "  return map[curr_state[0],curr_state[1]] == OBSTACLE\n",
        "\n",
        "def is_init(map,state):\n",
        "  return map[state[0],state[1]] == START\n",
        "\n",
        "def move(state,input):\n",
        "  new_vel = [state[2]+input[0],state[3]+input[1]]\n",
        "  new_state = [state[0]+new_vel[0],state[1]+new_vel[1]] + new_vel\n",
        "  return new_state,new_vel\n",
        "\n",
        "def behavior_policy(map,state):\n",
        "  act_idx = np.arange(actions.shape[0])\n",
        "  prob = 1\n",
        "  if is_init(map,state):\n",
        "    idx = np.where(actions[:,0] < 0)[0]\n",
        "    prob = 1/float(len(idx))\n",
        "    act_idx = idx\n",
        "  elif state[2]==0 and state[3] == 0:\n",
        "    idx = np.arange(actions.shape[0])\n",
        "    act_idx = np.delete(idx,[4])\n",
        "    prob = 1/float(len(act_idx))\n",
        "  if state[2] == 5:\n",
        "    idx = np.where(actions[:,0] < 1)[0]\n",
        "    prob = 1/float(len(idx))\n",
        "    act_idx = idx\n",
        "  elif state[2] == -5:\n",
        "    idx = np.where(actions[:,0] > -1)[0]\n",
        "    prob = 1/float(len(idx))\n",
        "    act_idx = idx\n",
        "  if state[3] == 5:\n",
        "    idx = np.where(actions[act_idx,1] < 1)[0]\n",
        "    prob = 1/float(len(idx))\n",
        "    act_idx = act_idx[idx]\n",
        "  elif state[3] == -5:\n",
        "    idx = np.where(actions[act_idx,1] > -1)[0]\n",
        "    prob = 1/float(len(idx))\n",
        "    act_idx = act_idx[idx]\n",
        "  if len(act_idx) == actions.shape[0]:\n",
        "    prob = 1/float(actions.shape[0])\n",
        "    act_idx = [np.random.choice(range(actions.shape[0]))]\n",
        "  return actions[np.random.choice(act_idx),:],np.round(prob,3)\n",
        "\n",
        "def get_action_idx(action):\n",
        "  return np.where(np.sum(np.abs(actions-action),1) == 0)[0][0]\n",
        "\n",
        "def play(map,init):\n",
        "  curr_state = np.copy(init)\n",
        "  reward = 0\n",
        "  traj = [curr_state]\n",
        "  action_prob = []\n",
        "  while not check_termination(map,curr_state):\n",
        "    reward -= 1\n",
        "    act,prob = behavior_policy(map,curr_state)\n",
        "    next_state,new_vel = move(curr_state,act)\n",
        "    # print(\"################\")\n",
        "    # print(curr_state)\n",
        "    # print(new_vel)\n",
        "    # print(next_state)\n",
        "    if check_OutOfBounds(map,next_state):\n",
        "      return -1,traj,action_prob\n",
        "      # curr_state = init_state(map)\n",
        "      # traj = [curr_state]\n",
        "      # action_prob = []\n",
        "      # continue\n",
        "    else:\n",
        "      curr_state = next_state\n",
        "    action_prob += [list(act) + [prob]]\n",
        "    traj += [curr_state]\n",
        "  return 1,traj,action_prob\n",
        "\n",
        "def target_policy(Q,state):\n",
        "  best_action = [np.argmax(Q[state[0],state[1],max_velocity+state[2],max_velocity+state[3],:])]\n",
        "  if len(best_action) < 1:\n",
        "    print('No Best Action')\n",
        "    print('State:',state)\n",
        "    print('Action:',Q[state[0],state[1],:])\n",
        "  return np.random.choice(best_action),np.round(1/float(len(best_action)),3)\n",
        "\n",
        "def play_target(map,Q,init):\n",
        "  curr_state = np.copy(init)\n",
        "  reward = 0\n",
        "  traj = [curr_state]\n",
        "  action_prob = []\n",
        "  while not check_termination(map,curr_state):\n",
        "    reward -= 1\n",
        "    a,prob = target_policy(Q,curr_state)\n",
        "    act = actions[a]\n",
        "    new_vel = [curr_state[2]+act[0],curr_state[3]+act[1]]\n",
        "    next_state = [curr_state[0]+new_vel[0],curr_state[1]+new_vel[1],new_vel[0],new_vel[1]] \n",
        "    if check_OutOfBounds(map,next_state):\n",
        "      # curr_state = init_state(map)\n",
        "      break\n",
        "    else:\n",
        "      curr_state = next_state\n",
        "    action_prob += [list(act) + [prob]]\n",
        "    traj += [curr_state]\n",
        "  return reward,traj,action_prob\n",
        "\n",
        "def MonteCarlo_OffPolicyControl(map,num_episodes):\n",
        "  nRows,nCols = map.shape\n",
        "  action_values  = np.zeros((nRows,nCols,2*max_velocity+1,2*max_velocity+1,len(actions)))\n",
        "  action_weights = np.zeros((nRows,nCols,2*max_velocity+1,2*max_velocity+1,len(actions)))\n",
        "\n",
        "  for episode in tqdm(range(num_episodes)):\n",
        "    init = init_state(map)\n",
        "    reward,traj,action_prob = play(map,init)\n",
        "    G = 0\n",
        "    W = 1\n",
        "    for i in range(len(traj)-2,-1,-1):\n",
        "      t = traj[i]\n",
        "      act_prob = action_prob[i]\n",
        "      G = reward#gamma*G + reward\n",
        "      act_idx = get_action_idx(np.array(act_prob[:2]))\n",
        "      action_weights[t[0],t[1],max_velocity+t[2],max_velocity+t[3],act_idx] += W\n",
        "      action_values[t[0],t[1],max_velocity+t[2],max_velocity+t[3],act_idx] += W/action_weights[t[0],t[1],max_velocity+t[2],max_velocity+t[3],act_idx]*(G-action_values[t[0],t[1],max_velocity+t[2],max_velocity+t[3],act_idx])\n",
        "      pi_t,_ = target_policy(action_values,t)\n",
        "      if pi_t != act_idx:\n",
        "        break\n",
        "      W = W/act_prob[-1]\n",
        "  return action_values\n",
        "\n",
        "def generate_path(map,Q):\n",
        "  final_map = []\n",
        "  for k in range(2):\n",
        "    init = init_state(map)\n",
        "    reward,traj,action_prob = play_target(map,Q,init)\n",
        "    print('Reward = :',reward)\n",
        "    final_map.append(np.copy(map))\n",
        "    for i,t in enumerate(traj):\n",
        "      final_map[-1][min(t[0],map.shape[0]-1),min(t[1],map.shape[1]-1)] = PATH\n",
        "  fig = plt.figure(figsize=(20,7))\n",
        "  plot_circuit(fig,final_map[0],1)\n",
        "  plot_circuit(fig,final_map[1],2)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym8vTXuD4Yta",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "598167ed-0cc4-4a66-a655-89c8b25532f7"
      },
      "source": [
        "num_episodes = 100000\n",
        "\n",
        "Q1 = MonteCarlo_OffPolicyControl(map_1,num_episodes)\n",
        "\n",
        "Q2 = MonteCarlo_OffPolicyControl(map_2,num_episodes)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [00:47<00:00, 2122.96it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWxqZOLa1mPI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "a72ea760-b2b2-47fe-86e6-715a77cd406e"
      },
      "source": [
        "generate_path(map1,Q1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reward = : -13\n",
            "Reward = : -14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0KO9IRTb-lQK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(behavior_policy(map,[0,0,-5,-5]))\n",
        "# idx = np.where(actions[:,0] > -1)[0]\n",
        "# prob = 1/float(len(idx))\n",
        "# act_idx = [np.random.choice(idx)]\n",
        "# print(act_idx)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JiV-P9FhlOp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "idx1 = np.where(actions[:,0] == 0)[0]\n",
        "idx2 = np.where(actions[idx1,1] == 0)[0]\n",
        "act_idx = idx1[idx2]\n",
        "idx = np.arange(actions.shape[0])\n",
        "act_idx = np.delete(idx,act_idx)\n",
        "print(actions[act_idx])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}