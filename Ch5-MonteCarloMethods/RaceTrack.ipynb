{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RaceTrack.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPs1dDwXUjxzRU+yiNdSy+O",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chandrusuresh/ReinforcementLearning/blob/master/Ch5-MonteCarloMethods/RaceTrack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToJb-Y89nKVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import colors\n",
        "%matplotlib inline\n",
        "from tqdm import tqdm\n",
        "from enum import Enum\n",
        "# np.random.seed(0)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzPO2dUE6EDS",
        "colab_type": "text"
      },
      "source": [
        "# Race Track\n",
        "\n",
        "This is the solution to Exercise-5.12 in Page-111 of the book [\"Reinforcement Learning\" by Barto, Sutton](http://incompleteideas.net/sutton/book/the-book.html).\n",
        "\n",
        "The summary of the problem is as follows:\n",
        "1. We have a map of a race track that is discretized by a grid of cells. Each cell corresponds to a position on the race track.\n",
        "2. The goal is to find the optimal path from a set of cells marked start line to another set of cells marked the finish line. For simplicity, the start line is assumed to be in the last row of the grid (bottom) and finish line is assumed to be in the last column of the grid (right).\n",
        "3. The track also has a set of valid & invalid cells. The invalid cells represent obstacles or out-of-bounds. No path is allowed to pass through an obstacle.\n",
        "4. Each time a path gets on a cell labelled obstacle, the position resets to a random start cell and the episode continues. The episode ends with the final state vector passes through or gets to any cell labeled finish line.\n",
        "5. The state vector is given by the position and velocity in the x & y directions. i.e. $\\text{state} = [p_x,p_y,v_x,v_y]$ where $p,v$ represent the position and velocity.\n",
        "5. The input vector is the acceleration at each time step given by: $\\text{input} = [a_x,a_y]$ where $a_x,a_y \\in \\{-1,0,1\\}$. The maximum number of possible actions is therefore (=3 $\\times$ 3) 9.\n",
        "6. In the simplest case, the state transition is a deterministic function of the current state and action. The state transition is computed as follows:\n",
        "$$ \\begin{align*} \\left[\\begin{matrix} p_x \\\\p_y \\\\ v_x \\\\ v_y\\end{matrix} \\right]_{k+1} &= \\left[ \\begin{matrix} 1 & 0 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\end{matrix}\\right] \\left[\\begin{matrix} p_x \\\\p_y \\\\ v_x \\\\ v_y\\end{matrix} \\right]_{k}+ \\left[ \\begin{matrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 0 \\\\ 0 & 1 \\end{matrix}\\right] \\left[ \\begin{matrix} a_x \\\\ a_y \\end{matrix}\\right]_k \\\\ \\\\\n",
        "\\Rightarrow s_{k+1} &= A s_k + B a_k \\end{align*}$$\n",
        "\n",
        "##### **Bonus Challenge**\n",
        "8. The above deterministic transition condition is relaxed as follows where the velocity increments (accleration input) are 0 with probability 0.1\n",
        "$$ \\Rightarrow s_{k+1} = \\Bigg\\{ \\begin{matrix} A s_k + B a_k & \\text{with probabilty=0.9} \\\\ A s_k & \\text{with probabilty=0.1} \\end{matrix}$$ \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Odvgucmx4eFL",
        "colab_type": "text"
      },
      "source": [
        "### Initialize Tracks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eS5tWIN7paU8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VALID = 0\n",
        "START = 1\n",
        "PATH = 2\n",
        "FINISH = 3\n",
        "OBSTACLE = 4\n",
        "\n",
        "def get_circuits():\n",
        "  nRows_1 = 32\n",
        "  nCols_1 = 17\n",
        "  map_1 = np.zeros((nRows_1,nCols_1),dtype=np.int8)\n",
        "  map_1[-1,3:9] = START\n",
        "  map_1[0:6,-1] = FINISH\n",
        "  map_1[-3:,:3] = OBSTACLE\n",
        "  map_1[-10:-3:,:2] = OBSTACLE\n",
        "  map_1[-18:-10:,:1] = OBSTACLE\n",
        "  map_1[0,:3] = OBSTACLE\n",
        "  map_1[1:3,:2] = OBSTACLE\n",
        "  map_1[3,:1] = OBSTACLE\n",
        "  map_1[7:,9:] = OBSTACLE\n",
        "  map_1[6,10:] = OBSTACLE\n",
        "\n",
        "  nRows_2 = 30\n",
        "  nCols_2 = 32\n",
        "  map_2 = np.zeros((nRows_2,nCols_2),dtype=np.int8)\n",
        "  map_2[-1,:23] = START\n",
        "  map_2[0:9,-1] = FINISH\n",
        "  map_2[-17:,23:] = OBSTACLE\n",
        "  map_2[-18:,24:] = OBSTACLE\n",
        "  map_2[-19:,26:] = OBSTACLE\n",
        "  map_2[-20:,27:] = OBSTACLE\n",
        "  map_2[-21:,30:] = OBSTACLE\n",
        "  map_2[0,:16] = OBSTACLE\n",
        "  map_2[[1,8],:13] = OBSTACLE\n",
        "  map_2[[2,7],:12] = OBSTACLE\n",
        "  map_2[3:7,:11] = OBSTACLE\n",
        "  map_2[9:14,:14] = OBSTACLE\n",
        "  c = 1\n",
        "  for i in range(14,nRows_2-2):\n",
        "    map_2[i,:14-c] = OBSTACLE\n",
        "    c += 1\n",
        "  return map_1,map_2\n",
        "\n",
        "def plot_circuit(fig,map,num):\n",
        "  nRows,nCols = map.shape\n",
        "  # create discrete colormap\n",
        "  #cmap = colors.ListedColormap(['red', 'blue'])\n",
        "  cmap = colors.ListedColormap(['white','red','blue','green','black'])\n",
        "  bounds = [0,0.1,3]\n",
        "  norm = colors.BoundaryNorm(bounds, cmap.N)\n",
        "  ax = fig.add_subplot(1,2,num)\n",
        "  ax.imshow(map, cmap=cmap)#, norm=norm)\n",
        "\n",
        "  ### draw gridlines\n",
        "  # ax = plt.gca();\n",
        "  ax.set_xticks(np.arange(-0.5, nCols+0.5, 1));\n",
        "  ax.set_yticks(np.arange(-0.5, nRows+0.5, 1));\n",
        "  ax.set_xticklabels(np.arange(-0.5, nCols+0.5, 1));\n",
        "  ax.set_yticklabels(np.arange(-0.5, nRows+0.5, 1));\n",
        "  ax.grid(color='k', linestyle='-', linewidth=1)\n",
        "\n",
        "  ax.set_xticklabels([])\n",
        "  ax.set_yticklabels([])\n",
        "  ax.xaxis.set_ticks_position('none')\n",
        "  ax.yaxis.set_ticks_position('none')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvRmT82s4hvM",
        "colab_type": "text"
      },
      "source": [
        "### Visualize Race Tracks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qyW-kHqz-Va",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "58385614-c622-4728-c6f3-907efffa5d9f"
      },
      "source": [
        "map_1,map_2 = get_circuits()\n",
        "fig = plt.figure(figsize=(20,7))#20,7)\n",
        "plot_circuit(fig,map_1,1)\n",
        "plot_circuit(fig,map_2,2)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wt-hLA3pBg74",
        "colab_type": "text"
      },
      "source": [
        "### Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ43rrCTBkD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_velocity = 5\n",
        "actions = np.array([[-1,-1],[-1,0],[-1,1],[0,-1],[0,0],[0,1],[1,-1],[1,0],[1,1]])\n",
        "gamma = 1.0\n",
        "A_mat = np.matrix([[1,0,1,0],[0,1,0,1],[0,0,1,0],[0,0,0,1]])\n",
        "B_mat = np.matrix([[1,0],[0,1],[1,0],[0,1]])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7J-6EiFmSPr",
        "colab_type": "text"
      },
      "source": [
        "## Path Finding\n",
        "\n",
        "First, we try to solve the relax the optimal requirement in the problem statement and focus just on being able to find a feasible trajectory from the start to finish line. For this, the Monte-Carlo Off-policy control algorithm in Page-111 of the book is used.\n",
        "1. Behavior policy. The behavior policy is set up to allow exploration of all states and satisfy the problem constraints simultaneously.\n",
        "2. The behavior policy is made restrictive to satisfy the problem constraints to allow more valid control inputs through the MC simulation. This allows a greater fraction of the episodes to terminate and leads to more coverage. In addition, encoding the known constraints in the behavior policy does not hurt exploration in any way. Some of these constraints are encoded in the behavior policy are as follows: \n",
        "\n",
        "*   The path is forbidden to leave the grid from the initial state. This is redundant since the condition for out-of-bounds is checked every step, but is included to speed up convergence\n",
        "*   The velocity components cannot both be zero at any cell other than the start line. This means that any action that makes the speed zero in any valid cell is forbidden by the behavior policy\n",
        "*   The speeds in both directions cannot exceed the max speed limit of 5 units. So the acceleration inputs that increase/decrease the velocith below this threshold are forbidden.\n",
        "\n",
        ">   The behavior policy chooses the actions that satisfy the above constraints with equal probability.\n",
        "\n",
        "3. This part of the problem focusses only on path-finding, therefore the reward is therefore modified to be terminal and all states in the trajectory are given a reward of +1 on reaching the finish line and -1 for going out-of-bounds.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-rplh5P5KOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_state(map):\n",
        "  find_start_line = np.where(map == START)\n",
        "  choice = np.random.choice(range(len(find_start_line[0])))\n",
        "  init = [find_start_line[0][choice],find_start_line[1][choice],0,0]\n",
        "  return init\n",
        "\n",
        "def check_termination(map,curr_state):\n",
        "  finish_line = np.where(map == FINISH)\n",
        "  return curr_state[1] >= finish_line[1][0] and curr_state[0] >= np.min(finish_line[0]) and curr_state[0] <= np.max(finish_line[0])\n",
        "\n",
        "def check_OutOfBounds(map,curr_state):\n",
        "  if min(curr_state[0],curr_state[1]) < 0:\n",
        "    return True\n",
        "  elif check_termination(map,curr_state):\n",
        "    return False\n",
        "  elif curr_state[1] >= map.shape[1] or curr_state[0] >= map.shape[0]:\n",
        "    return True\n",
        "  return map[curr_state[0],curr_state[1]] == OBSTACLE\n",
        "\n",
        "def is_init(map,state):\n",
        "  return map[state[0],state[1]] == START\n",
        "\n",
        "def move(state,input):\n",
        "  new_vel = [state[2]+input[0],state[3]+input[1]]\n",
        "  new_state = [state[0]+new_vel[0],state[1]+new_vel[1]] + new_vel\n",
        "  return new_state,new_vel\n",
        "\n",
        "def behavior_policy(map,state):\n",
        "  act_idx = np.arange(actions.shape[0])\n",
        "  prob = 1\n",
        "  if is_init(map,state):\n",
        "    idx = np.where(actions[:,0] < 0)[0]\n",
        "    prob = 1/float(len(idx))\n",
        "    act_idx = idx\n",
        "  # elif state[2]==0 and state[3] == 0:\n",
        "  #   idx = np.arange(actions.shape[0])\n",
        "  #   act_idx = np.delete(idx,[4])\n",
        "  #   prob = 1/float(len(act_idx))\n",
        "  else:\n",
        "    idx = [i for i in range(actions.shape[0]) if state[2]+actions[i,0] == 0 and state[3]+actions[i,1] == 0]\n",
        "    act_idx = np.delete(act_idx,idx)\n",
        "    prob = 1/float(len(act_idx))\n",
        "  if state[2] == max_velocity:\n",
        "    idx = np.where(actions[:,0] < 1)[0]\n",
        "    prob = 1/float(len(idx))\n",
        "    act_idx = idx\n",
        "  elif state[2] == -max_velocity:\n",
        "    idx = np.where(actions[:,0] > -1)[0]\n",
        "    prob = 1/float(len(idx))\n",
        "    act_idx = idx\n",
        "  if state[3] == max_velocity:\n",
        "    idx = np.where(actions[act_idx,1] < 1)[0]\n",
        "    prob = 1/float(len(idx))\n",
        "    act_idx = act_idx[idx]\n",
        "  elif state[3] == -max_velocity:\n",
        "    idx = np.where(actions[act_idx,1] > -1)[0]\n",
        "    prob = 1/float(len(idx))\n",
        "    act_idx = act_idx[idx]\n",
        "  if len(act_idx) == actions.shape[0]:\n",
        "    prob = 1/float(actions.shape[0])\n",
        "    act_idx = [np.random.choice(range(actions.shape[0]))]\n",
        "  return actions[np.random.choice(act_idx),:],np.round(prob,3)\n",
        "\n",
        "def get_action_idx(action):\n",
        "  return np.where(np.sum(np.abs(actions-action),1) == 0)[0][0]\n",
        "\n",
        "def play(map,init):\n",
        "  curr_state = np.copy(init)\n",
        "  reward = 0\n",
        "  traj = [curr_state]\n",
        "  action_prob = []\n",
        "  while not check_termination(map,curr_state):\n",
        "    reward -= 1\n",
        "    act,prob = behavior_policy(map,curr_state)\n",
        "    next_state,new_vel = move(curr_state,act)\n",
        "    # print(\"################\")\n",
        "    # print(curr_state)\n",
        "    # print(new_vel)\n",
        "    # print(next_state)\n",
        "    if check_OutOfBounds(map,next_state):\n",
        "      return -1,traj,action_prob\n",
        "      # curr_state = init_state(map)\n",
        "      # traj = [curr_state]\n",
        "      # action_prob = []\n",
        "      # continue\n",
        "    else:\n",
        "      curr_state = next_state\n",
        "    action_prob += [list(act) + [prob]]\n",
        "    traj += [curr_state]\n",
        "  return 1,traj,action_prob\n",
        "\n",
        "def target_policy(Q,state):\n",
        "  best_action = [np.argmax(Q[state[0],state[1],max_velocity+state[2],max_velocity+state[3],:])]\n",
        "  if len(best_action) < 1:\n",
        "    print('No Best Action')\n",
        "    print('State:',state)\n",
        "    print('Action:',Q[state[0],state[1],:])\n",
        "  return np.random.choice(best_action),np.round(1/float(len(best_action)),3)\n",
        "\n",
        "def play_target(map,Q,init):\n",
        "  curr_state = np.copy(init)\n",
        "  reward = 0\n",
        "  traj = [curr_state]\n",
        "  action_prob = []\n",
        "  while not check_termination(map,curr_state):\n",
        "    reward -= 1\n",
        "    a,prob = target_policy(Q,curr_state)\n",
        "    act = actions[a]\n",
        "    new_vel = [curr_state[2]+act[0],curr_state[3]+act[1]]\n",
        "    next_state = [curr_state[0]+new_vel[0],curr_state[1]+new_vel[1],new_vel[0],new_vel[1]] \n",
        "    if check_OutOfBounds(map,next_state):\n",
        "      # curr_state = init_state(map)\n",
        "      break\n",
        "    else:\n",
        "      curr_state = next_state\n",
        "    action_prob += [list(act) + [prob]]\n",
        "    traj += [curr_state]\n",
        "  return reward,traj,action_prob\n",
        "\n",
        "def MonteCarlo_OffPolicyControl(map,num_episodes):\n",
        "  nRows,nCols = map.shape\n",
        "  action_values  = np.zeros((nRows,nCols,2*max_velocity+1,2*max_velocity+1,len(actions)))\n",
        "  action_weights = np.zeros((nRows,nCols,2*max_velocity+1,2*max_velocity+1,len(actions)))\n",
        "\n",
        "  for episode in tqdm(range(num_episodes)):\n",
        "    init = init_state(map)\n",
        "    reward,traj,action_prob = play(map,init)\n",
        "    G = 0\n",
        "    W = 1\n",
        "    for i in range(len(traj)-2,-1,-1):\n",
        "      t = traj[i]\n",
        "      act_prob = action_prob[i]\n",
        "      G = reward#gamma*G + reward\n",
        "      act_idx = get_action_idx(np.array(act_prob[:2]))\n",
        "      action_weights[t[0],t[1],max_velocity+t[2],max_velocity+t[3],act_idx] += W\n",
        "      action_values[t[0],t[1],max_velocity+t[2],max_velocity+t[3],act_idx] += W/action_weights[t[0],t[1],max_velocity+t[2],max_velocity+t[3],act_idx]*(G-action_values[t[0],t[1],max_velocity+t[2],max_velocity+t[3],act_idx])\n",
        "      pi_t,_ = target_policy(action_values,t)\n",
        "      if pi_t != act_idx:\n",
        "        break\n",
        "      W = W/act_prob[-1]\n",
        "  return action_values\n",
        "\n",
        "def generate_path(map,Q):\n",
        "  final_map = []\n",
        "  for k in range(2):\n",
        "    init = init_state(map)\n",
        "    reward,traj,action_prob = play_target(map,Q,init)\n",
        "    print('Reward = :',reward)\n",
        "    final_map.append(np.copy(map))\n",
        "    for i,t in enumerate(traj):\n",
        "      final_map[-1][min(t[0],map.shape[0]-1),min(t[1],map.shape[1]-1)] = PATH\n",
        "  fig = plt.figure(figsize=(20,7))\n",
        "  plot_circuit(fig,final_map[0],1)\n",
        "  plot_circuit(fig,final_map[1],2)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VoMxzO-Ar5Qb",
        "colab_type": "text"
      },
      "source": [
        "## Monte-Carlo Off-Policy Control"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ym8vTXuD4Yta",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "4caac7b8-0bf7-44e1-8b4f-1d7c683a55ec"
      },
      "source": [
        "num_episodes = 100000\n",
        "\n",
        "Q1 = MonteCarlo_OffPolicyControl(map_1,num_episodes)\n",
        "\n",
        "Q2 = MonteCarlo_OffPolicyControl(map_2,num_episodes)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [00:56<00:00, 1760.42it/s]\n",
            "100%|██████████| 100000/100000 [01:28<00:00, 1130.54it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWxqZOLa1mPI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "2ddf2f1a-91ba-496b-8032-5e43e559b7fb"
      },
      "source": [
        "generate_path(map_1,Q1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reward = : -12\n",
            "Reward = : -18\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLJxeHhhvavI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "ef8b6d72-3f7b-4cb3-c52d-d02c157b799d"
      },
      "source": [
        "generate_path(map_2,Q2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reward = : -12\n",
            "Reward = : -11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJv5cvuGMCV3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def play_opt(map,init):\n",
        "  curr_state = np.copy(init)\n",
        "  reward = 0\n",
        "  traj = [curr_state]\n",
        "  action_prob = []\n",
        "  while not check_termination(map,curr_state):\n",
        "    reward -= 1\n",
        "    act,prob = behavior_policy(map,curr_state)\n",
        "    next_state,new_vel = move(curr_state,act)\n",
        "    if check_OutOfBounds(map,next_state):\n",
        "      return -100,traj,action_prob\n",
        "    else:\n",
        "      curr_state = next_state\n",
        "    action_prob += [list(act) + [prob]]\n",
        "    traj += [curr_state]\n",
        "  return reward,traj,action_prob\n",
        "\n",
        "def generate_opt_path(map,Q):\n",
        "  final_map = []\n",
        "  for k in range(2):\n",
        "    init = init_state(map)\n",
        "    # reward,traj,action_prob = play_target(map,Q,init)\n",
        "    reward,traj,action_prob = play_opt(map,init)\n",
        "    print('Reward = :',reward)\n",
        "    final_map.append(np.copy(map))\n",
        "    for i,t in enumerate(traj):\n",
        "      final_map[-1][min(t[0],map.shape[0]-1),min(t[1],map.shape[1]-1)] = PATH\n",
        "  fig = plt.figure(figsize=(20,7))\n",
        "  plot_circuit(fig,final_map[0],1)\n",
        "  plot_circuit(fig,final_map[1],2)\n",
        "\n",
        "def MonteCarlo_OffPolicyOptimalControl(map,num_episodes):\n",
        "  nRows,nCols = map.shape\n",
        "  action_values  = np.zeros((nRows,nCols,2*max_velocity+1,2*max_velocity+1,len(actions)))\n",
        "  action_weights = np.zeros((nRows,nCols,2*max_velocity+1,2*max_velocity+1,len(actions)))\n",
        "\n",
        "  for episode in tqdm(range(num_episodes)):\n",
        "    init = init_state(map)\n",
        "    reward,traj,action_prob = play_opt(map,init)\n",
        "    G = 0\n",
        "    W = 1\n",
        "    for i in range(len(traj)-2,-1,-1):\n",
        "      t = traj[i]\n",
        "      act_prob = action_prob[i]\n",
        "      G = reward#gamma*G + reward\n",
        "      act_idx = get_action_idx(np.array(act_prob[:2]))\n",
        "      action_weights[t[0],t[1],max_velocity+t[2],max_velocity+t[3],act_idx] += W\n",
        "      action_values[t[0],t[1],max_velocity+t[2],max_velocity+t[3],act_idx] += W/action_weights[t[0],t[1],max_velocity+t[2],max_velocity+t[3],act_idx]*(G-action_values[t[0],t[1],max_velocity+t[2],max_velocity+t[3],act_idx])\n",
        "      pi_t,prob_t = target_policy(action_values,t)\n",
        "      # if pi_t != act_idx:\n",
        "      #   break\n",
        "      # print(\"out of break\")\n",
        "      W = W*prob_t/act_prob[-1]\n",
        "  return action_values\n",
        "\n",
        "def opt_target_policy(Q,state):\n",
        "  Q_val = Q[state[0],state[1],max_velocity+state[2],max_velocity+state[3],:]\n",
        "  idx = np.where(Q_val != 0)[0]\n",
        "  best_action = [idx[np.argmax(Q_val[idx])]]\n",
        "  return np.random.choice(best_action),np.round(1/float(len(best_action)),3)\n",
        "\n",
        "def play_opt_target(map,Q,init):\n",
        "  curr_state = np.copy(init)\n",
        "  reward = 0\n",
        "  traj = [curr_state]\n",
        "  action_prob = []\n",
        "  while not check_termination(map,curr_state):\n",
        "    reward -= 1\n",
        "    a,prob = opt_target_policy(Q,curr_state)\n",
        "    act = actions[a]\n",
        "    new_vel = [curr_state[2]+act[0],curr_state[3]+act[1]]\n",
        "    next_state = [curr_state[0]+new_vel[0],curr_state[1]+new_vel[1],new_vel[0],new_vel[1]] \n",
        "    if check_OutOfBounds(map,next_state):\n",
        "      # curr_state = init_state(map)\n",
        "      break\n",
        "    else:\n",
        "      curr_state = next_state\n",
        "    action_prob += [list(act) + [prob]]\n",
        "    traj += [curr_state]\n",
        "  return reward,traj,action_prob\n",
        "\n",
        "def generate_opt_path(map,Q):\n",
        "  final_map = []\n",
        "  for k in range(2):\n",
        "    init = init_state(map)\n",
        "    reward,traj,action_prob = play_opt_target(map,Q,init)\n",
        "    print('Reward = :',reward)\n",
        "    final_map.append(np.copy(map))\n",
        "    for i,t in enumerate(traj):\n",
        "      final_map[-1][min(t[0],map.shape[0]-1),min(t[1],map.shape[1]-1)] = PATH\n",
        "  fig = plt.figure(figsize=(20,7))\n",
        "  plot_circuit(fig,final_map[0],1)\n",
        "  plot_circuit(fig,final_map[1],2)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXcu76mWNSO8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "239cbe81-41cb-40c8-aa7d-bd1b9b321e37"
      },
      "source": [
        "num_episodes = 100000\n",
        "\n",
        "Q1_opt = MonteCarlo_OffPolicyOptimalControl(map_1,num_episodes)\n",
        "\n",
        "# Q2_opt = MonteCarlo_OffPolicyOptimalControl(map_2,num_episodes)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100000/100000 [01:14<00:00, 1347.45it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8U9QbrwMyq9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "38130162-f9cd-4d20-b801-5b8181e23ec5"
      },
      "source": [
        "generate_opt_path(map_1,Q1_opt)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reward = : -20\n",
            "Reward = : -17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGgilY-2SjxY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "e6c2eafe-6700-418a-edfb-6936a3803f5d"
      },
      "source": [
        "x = 31\n",
        "y = 3\n",
        "print(Q1_opt[x,y,5,5,:])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[  0.         -28.2570801  -99.94927057   0.           0.\n",
            "   0.           0.           0.           0.        ]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}